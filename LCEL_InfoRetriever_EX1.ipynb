{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16de7336",
   "metadata": {},
   "source": [
    "# Tagging and Extraction Using OpenAI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15626162-c934-4618-a9c8-fee6c522c95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "####.  Please use VirttualEnv: LCEL_inforetrieve\n",
    "####.  Please use VirttualEnv: LCEL_inforetrieve\n",
    "####.  Please use VirttualEnv: LCEL_inforetrieve\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "print(os.environ[\"OPENAI_API_KEY\"]),\n",
    "OPENAI_API_KEY=os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7824e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75dc4a0-a224-4ed4-bcdb-4c4bde38b330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain==0.2.15\r\n",
      "langchain-core==0.2.41\r\n",
      "langchain-openai==0.1.23\r\n",
      "langchain-text-splitters==0.2.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a00bb1-badc-4417-a143-922dc48b6f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain-openai==0.1.23\r\n",
      "openai==1.47.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e6ec97-58ec-49ff-811f-5cb2a7723d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pydantic==2.9.2\r\n",
      "pydantic_core==2.23.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3fe5c",
   "metadata": {},
   "source": [
    "## Tagging\n",
    "\n",
    "Before we used function to extract specific API parameters from a natural langugage input.\n",
    " \n",
    "Here, we show that functions are very flexible. \n",
    "\n",
    "We use them to easily tag a piece of text with particular info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49d99bd6-7350-4f64-b6a1-a53515e647c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46af2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tagging(BaseModel):\n",
    "    \"\"\"Tag the piece of text with particular info.\"\"\"\n",
    "    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\")\n",
    "    language: str = Field(description=\"language of text (should be ISO 639-1 code)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d40404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/ffmtyr9j47nccz_6s1wjrlzh0000gp/T/ipykernel_4030/1482288838.py:1: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  convert_pydantic_to_openai_function(Tagging)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Tagging',\n",
       " 'description': 'Tag the piece of text with particular info.',\n",
       " 'parameters': {'properties': {'sentiment': {'description': 'sentiment of text, should be `pos`, `neg`, or `neutral`',\n",
       "    'type': 'string'},\n",
       "   'language': {'description': 'language of text (should be ISO 639-1 code)',\n",
       "    'type': 'string'}},\n",
       "  'required': ['sentiment', 'language'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Tagging)\n",
    "#convert_to_openai_function(Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01832ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"sentiment\":\"pos\",\"language\":\"en\"}', 'name': 'Tagging'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 108, 'total_tokens': 118, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a490c550-0b72-4bf7-883a-50c97e132b5e-0', usage_metadata={'input_tokens': 108, 'output_tokens': 10, 'total_tokens': 118})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "tagging_functions = [convert_pydantic_to_openai_function(Tagging)]\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Think carefully, and then tag the text as instructed.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "# We pass function_call to MAKE it call this function\n",
    "model_with_functions = model.bind(functions=tagging_functions, function_call={\"name\":\"Tagging\"})\n",
    "tagging_chain = prompt | model_with_functions\n",
    "tagging_chain.invoke({\"input\": \"I love LangChain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84163142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"sentiment\":\"neg\",\"language\":\"it\"}', 'name': 'Tagging'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 111, 'total_tokens': 121, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-47d8df52-5439-4443-ae42-4091a8a043b1-0', usage_metadata={'input_tokens': 111, 'output_tokens': 10, 'total_tokens': 121})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703be8e2",
   "metadata": {},
   "source": [
    "We can use an output parser to automatically extract this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a2981d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'neg', 'language': 'it'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "tagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()\n",
    "tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4519d",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "Extraction is similar to tagging, but used for extracting multiple pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa75472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"person's name\")\n",
    "    age: Optional[int] = Field(description=\"person's age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "736b10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"List of info about people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88ed1ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"people\":[{\"name\":\"Joe\",\"age\":30},{\"name\":\"Martha\",\"age\":null}]}', 'name': 'Information'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 96, 'total_tokens': 117, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6c5368c7-d588-452a-bd5c-0467ccbc7512-0', usage_metadata={'input_tokens': 96, 'output_tokens': 21, 'total_tokens': 117})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_functions = [convert_pydantic_to_openai_function(Information)]\n",
    "extraction_model = model.bind(functions=extraction_functions, function_call={\"name\":\"Information\"})\n",
    "extraction_model.invoke(\"Joe is 30. Joe's mom is Martha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b62f305",
   "metadata": {},
   "source": [
    "Similarly we can use a separate output parser to pluck that \"Information\" key, since that's the information we really care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19deb56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Joe', 'age': 30}, {'name': 'Martha', 'age': None}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "extraction_chain = extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")\n",
    "extraction_chain.invoke(\"Joe is 30. Joe's mom is Martha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11486d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bbaa189-a553-47f9-9f29-2d85e3991c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "492da33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Joe', 'age': 30}, {'name': 'Martha', 'age': None}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"Joe is 30. Joe's mom is Martha\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6371731-a98f-4d25-a6a0-cdf61925815b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcel_tagging",
   "language": "python",
   "name": "lcel_tagging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
